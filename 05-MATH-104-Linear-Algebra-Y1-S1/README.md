# MATH 104 - Linear Algebra (Y1-S1)

<div align="center">

**Fall 2021** | **Mathematical Foundation**

[![Materials](https://img.shields.io/badge/Materials-Complete-success)](.)
[![Skills](https://img.shields.io/badge/Skills-Matrices%20|%20Vectors%20|%20Eigenvalues-orange)](.)

</div>

---

## ğŸ“‹ Course Overview

Comprehensive linear algebra course covering vector spaces, matrices, linear transformations, eigenvalues, and applications. Essential mathematical foundation for machine learning, deep learning, and data science where linear algebra operations are fundamental.

---

## ğŸ¯ Learning Outcomes Achieved

### Theoretical Mastery
- âœ… Vector spaces and subspaces
- âœ… Matrix operations and properties
- âœ… Linear transformations
- âœ… Eigenvalues and eigenvectors
- âœ… Orthogonality and projections

### Computational Skills
- âœ… Matrix decompositions (LU, QR, SVD)
- âœ… Solving linear systems
- âœ… Determinants and inverses
- âœ… Numerical linear algebra basics

---

## ğŸ“š Topics Covered

### Module 1: Vectors and Matrices (Weeks 1-4)
- Vector operations and properties
- Matrix operations (addition, multiplication)
- Matrix transpose and properties
- Special matrices (identity, diagonal, symmetric)

### Module 2: Linear Systems (Weeks 5-7)
- Gaussian elimination
- Row echelon form and RREF
- Solution existence and uniqueness
- LU decomposition

### Module 3: Vector Spaces (Weeks 8-10)
- Vector spaces and subspaces
- Linear independence and span
- Basis and dimension
- Null space and column space

### Module 4: Eigenanalysis (Weeks 11-13)
- Eigenvalues and eigenvectors
- Characteristic polynomial
- Diagonalization
- Applications to dynamical systems

### Module 5: Advanced Topics (Week 14)
- Singular Value Decomposition (SVD)
- Principal Component Analysis (PCA)
- Least squares applications

---

## ğŸ› ï¸ Technical Skills Developed

### Mathematical Tools
- **NumPy**: Matrix operations in Python
- **MATLAB/Octave**: Linear algebra computations
- **Analytical Skills**: Proof techniques

---

## ğŸ¯ Relevance to AI/ML

Linear algebra is the backbone of:
- **Neural Networks**: Weight matrices, transformations
- **PCA**: Dimensionality reduction
- **Recommender Systems**: Matrix factorization
- **Computer Vision**: Image transformations
- **NLP**: Word embeddings, attention matrices

---

## ğŸ“– Key Resources

### Textbooks
- **"Linear Algebra and Its Applications"** - Gilbert Strang
- **"Introduction to Linear Algebra"** - Gilbert Strang

### Online Resources
- MIT 18.06 Linear Algebra (Gilbert Strang lectures)

---

<div align="center">

**Key Takeaway**: Linear algebra is the language of data - every ML model relies on matrix operations.

[â¬…ï¸ Back to All Courses](../README.md#-complete-course-catalog)

</div>
