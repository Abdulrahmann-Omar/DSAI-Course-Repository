{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Team Member\n",
        "=================================\n",
        "Omar Eldesoukey \t   ========    202202155\n",
        "\n",
        "Abdallah Saed \t ========      202201933\n",
        "\n",
        "Alhassan\t    ========         202200681\n",
        "\n",
        "Abdulrahman Omar\t ========    202202254\n"
      ],
      "metadata": {
        "id": "Zfo-iuTQZlIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The first question"
      ],
      "metadata": {
        "id": "NcCl-ghg0L6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "uDUbHpIY0S22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "   Fibonacci Method for 1Dimensional minimization"
      ],
      "metadata": {
        "id": "v8lGmtgb0UwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fibonacci_method(f, a, b, tol=1e-5, max_iter=200):\n",
        "\n",
        "    fib = [1, 1]\n",
        "    for i in range(2, max_iter):\n",
        "        fib.append(fib[-1] + fib[-2])\n",
        "\n",
        "    n = len(fib) - 1\n",
        "\n",
        "    x1 = a + (fib[n - 2] / fib[n]) * (b - a)\n",
        "    x2 = a + (fib[n - 1] / fib[n]) * (b - a)\n",
        "\n",
        "    f1 = f(x1)\n",
        "    f2 = f(x2)\n",
        "\n",
        "    for k in range(n - 2, 0, -1):\n",
        "        if f1 > f2:\n",
        "            a = x1\n",
        "            x1 = x2\n",
        "            f1 = f2\n",
        "            x2 = a + (fib[k - 1] / fib[k]) * (b - a)\n",
        "            f2 = f(x2)\n",
        "        else:\n",
        "            b = x2\n",
        "            x2 = x1\n",
        "            f2 = f1\n",
        "            x1 = a + (fib[k - 2] / fib[k]) * (b - a)\n",
        "            f1 = f(x1)\n",
        "\n",
        "        if abs(b - a) < tol:\n",
        "            break\n",
        "\n",
        "    if f1 < f2:\n",
        "        return x1, f1\n",
        "    else:\n",
        "        return x2, f2\n",
        "\n",
        "def example_function(x):\n",
        "    return (x - 3)**2 + 1\n",
        "\n",
        "a = 1\n",
        "b = 10\n",
        "\n",
        "minimum_point, min_value = fibonacci_method(example_function, a, b, tol=1e-5, max_iter=200)\n",
        "\n",
        "\n",
        "print(f\"Approximate minimum point: {minimum_point}\")\n",
        "print(f\"Function value at the minimum: {min_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9PDTlhX0kEm",
        "outputId": "c730ce31-6286-48bb-e4b0-1787a2a8524f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Approximate minimum point: 3.000001201865295\n",
            "Function value at the minimum: 1.0000000000014444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Golden Section Method for one-dimensional minimization"
      ],
      "metadata": {
        "id": "C41b9gNG0tTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def golden_section_search(f, a, b, tol=1e-5):\n",
        "    phi = (1 + np.sqrt(5)) / 2\n",
        "    resphi = 2 - phi\n",
        "    c = a + resphi * (b - a)\n",
        "    d = b - resphi * (b - a)\n",
        "    fc = f(c)\n",
        "    fd = f(d)\n",
        "\n",
        "    while (b - a) > tol:\n",
        "        if fc < fd:\n",
        "            b = d\n",
        "            d = c\n",
        "            fd = fc\n",
        "            c = a + resphi * (b - a)\n",
        "            fc = f(c)\n",
        "        else:\n",
        "            a = c\n",
        "            c = d\n",
        "            fc = fd\n",
        "            d = b - resphi * (b - a)\n",
        "            fd = f(d)\n",
        "\n",
        "    if fc < fd:\n",
        "        return c, fc\n",
        "    else:\n",
        "        return d, fd\n",
        "\n",
        "def example_function(x):\n",
        "    return (x - 3)**2 + 1\n",
        "\n",
        "a = 1\n",
        "b = 10\n",
        "\n",
        "minimum_point, min_value = golden_section_search(example_function, a, b)\n",
        "\n",
        "print(f\"Approximate minimum point: {minimum_point}\")\n",
        "print(f\"Function value at the minimum: {min_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW1kGGUj0wRy",
        "outputId": "f0c9cee2-0322-4aca-edda-d1707531b10b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Approximate minimum point: 3.0000012018652944\n",
            "Function value at the minimum: 1.0000000000014444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Newton's Method for one-dimensional minimization\n"
      ],
      "metadata": {
        "id": "BOFGc0Tf0_RQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def newton_method(f, df, d2f, x0, tol=1e-5, max_iter=100):\n",
        "    x = x0\n",
        "    for i in range(max_iter):\n",
        "        fx = f(x)\n",
        "        dfx = df(x)\n",
        "        d2fx = d2f(x)\n",
        "        if abs(dfx) < tol:\n",
        "            break\n",
        "        x = x - dfx / d2fx\n",
        "    return x, f(x)\n",
        "\n",
        "def example_function(x):\n",
        "    return (x - 3)**2 + 1\n",
        "\n",
        "def example_derivative(x):\n",
        "    return 2 * (x - 3)\n",
        "\n",
        "def example_second_derivative(x):\n",
        "    return 2\n",
        "\n",
        "x0 = 0\n",
        "minimum_point, min_value = newton_method(example_function, example_derivative, example_second_derivative, x0)\n",
        "\n",
        "print(f\"Minimum point: {minimum_point}\")\n",
        "print(f\"Function value at minimum: {min_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLDTdDFO1AjI",
        "outputId": "a27489d5-3afc-4f9c-ec53-c94187849638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum point: 3.0\n",
            "Function value at minimum: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quasi-Newton method for 1D minimization\n"
      ],
      "metadata": {
        "id": "g_27orRf1Dng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quasi_newton_method(f, df, x0, tol=1e-5, max_iter=100):\n",
        "    x = x0\n",
        "    H = 1.0\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        dfx = df(x)\n",
        "        if abs(dfx) < tol:\n",
        "            break\n",
        "        p = -H * dfx\n",
        "        x_new = x + p\n",
        "        s = x_new - x\n",
        "        y = df(x_new) - dfx\n",
        "\n",
        "        if abs(y) > 1e-10:\n",
        "            rho = 1.0 / y\n",
        "            H = (1 - rho * s) * H\n",
        "\n",
        "        x = x_new\n",
        "\n",
        "    return x, f(x)\n",
        "\n",
        "def example_function(x):\n",
        "    return x**3 - 6*x**2 + 11*x - 6\n",
        "\n",
        "def example_derivative(x):\n",
        "    return 3*x**2 - 12*x + 11\n",
        "\n",
        "x0 = 2\n",
        "\n",
        "minimum_point, min_value = quasi_newton_method(example_function, example_derivative, x0)\n",
        "\n",
        "print(f\"Minimum point: {minimum_point}\")\n",
        "print(f\"Function value at the minimum: {min_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA4P3RYY1GZT",
        "outputId": "84389403-3b48-4bdd-e7fc-c73c10a050f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum point: 2.4616194957738826\n",
            "Function value at the minimum: -0.3632518161912017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Secant method for 1D minimization"
      ],
      "metadata": {
        "id": "Cyb9qvrV3VFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def gradient_descent(f, df, x0, tol=1e-5, max_iter=100, learning_rate=0.1):\n",
        "    x = x0\n",
        "    iter_count = 0\n",
        "    while iter_count < max_iter:\n",
        "        gradient = df(x)\n",
        "        x_new = x - learning_rate * gradient\n",
        "        if abs(x_new - x) < tol:\n",
        "            return x_new\n",
        "        x = x_new\n",
        "        iter_count += 1\n",
        "    print(\"Warning: Maximum iterations reached.\")\n",
        "    return x\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    def example_function(x):\n",
        "        return x**2 - 4*x + 4\n",
        "\n",
        "    def example_derivative(x):\n",
        "        return 2*x - 4\n",
        "    x0 = 0\n",
        "    minimum = gradient_descent(example_function, example_derivative, x0)\n",
        "\n",
        "    if minimum is not None:\n",
        "        print(f\"Minimum point: {minimum}\")\n",
        "        print(f\"Function value at the minimum: {example_function(minimum)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoSJT-rN3VVZ",
        "outputId": "c734a2b4-1090-436d-f944-e1fdac6179d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum point: 1.9999643188076823\n",
            "Function value at the minimum: 1.2731473653104786e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Part-2***"
      ],
      "metadata": {
        "id": "Ed9jxgT0yY6d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Fletcher-Reeves CG Method.***"
      ],
      "metadata": {
        "id": "Y1NdyRlkygra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fletcher_reeves_cg(f, grad_f, x0, tol=1e-6, max_iter=1000):\n",
        "    x = x0\n",
        "    g = grad_f(x)\n",
        "    d = -g\n",
        "    k = 0\n",
        "\n",
        "    while np.linalg.norm(g) > tol and k < max_iter:\n",
        "        alpha = line_search(f, grad_f, x, d)\n",
        "        x_new = x + alpha * d\n",
        "        g_new = grad_f(x_new)\n",
        "        beta = np.dot(g_new, g_new) / np.dot(g, g)\n",
        "        d = -g_new + beta * d\n",
        "        x = x_new\n",
        "        g = g_new\n",
        "        k += 1\n",
        "\n",
        "    return x, f(x), k"
      ],
      "metadata": {
        "id": "OSFPre_5x2_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Marquardt Method.***"
      ],
      "metadata": {
        "id": "304AcTgzyjSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def marquardt_method(f, grad_f, hess_f, x0, mu=1e-3, tol=1e-6, max_iter=100):\n",
        "    x = x0\n",
        "    k = 0\n",
        "    while k < max_iter:\n",
        "        grad = grad_f(x)\n",
        "        if np.linalg.norm(grad) < tol:\n",
        "            break\n",
        "        H = hess_f(x)\n",
        "        H_mod = H + mu * np.eye(len(x0))\n",
        "        try:\n",
        "            p = -np.linalg.solve(H_mod, grad)\n",
        "        except np.linalg.LinAlgError:\n",
        "            mu *= 10\n",
        "            continue\n",
        "        x_new = x + p\n",
        "        if f(x_new) < f(x):\n",
        "            x = x_new\n",
        "            mu /= 10\n",
        "        else:\n",
        "            mu *= 10\n",
        "        k += 1\n",
        "    return x, f(x), k"
      ],
      "metadata": {
        "id": "hpEBYZZ6x28d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Quasi-Newton Method.***"
      ],
      "metadata": {
        "id": "Lrxpv_Ohytm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quasi_newton_method(f, grad_f, x0, tol=1e-6, max_iter=100):\n",
        "    x = x0\n",
        "    k = 0\n",
        "    B = np.eye(len(x0))\n",
        "\n",
        "    while k < max_iter:\n",
        "        grad = grad_f(x)\n",
        "        if np.linalg.norm(grad) < tol:\n",
        "            break\n",
        "\n",
        "        p = -np.linalg.solve(B, grad)\n",
        "        alpha = line_search(f, grad_f, x, p)\n",
        "        x_new = x + alpha * p\n",
        "        s = x_new - x\n",
        "        y = grad_f(x_new) - grad\n",
        "\n",
        "        if np.dot(s, y) > 0:\n",
        "            B += np.outer(y, y) / np.dot(y, s) - np.outer(B @ s, B @ s) / (s @ B @ s)\n",
        "\n",
        "        x = x_new\n",
        "        k += 1\n",
        "\n",
        "    return x, f(x), k"
      ],
      "metadata": {
        "id": "ziDWFfHqx24x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Backtracking Line Search***"
      ],
      "metadata": {
        "id": "lZFJxA8Hzinb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def line_search(f, grad_f, x, d, alpha_init=1.0, rho=0.9, c=1e-4):\n",
        "    alpha = alpha_init\n",
        "    while f(x + alpha * d) > f(x) + c * alpha * np.dot(grad_f(x), d):\n",
        "        alpha *= rho\n",
        "    return alpha"
      ],
      "metadata": {
        "id": "Tjoge9ilyFi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Example usage***"
      ],
      "metadata": {
        "id": "c3CR5TEHy2Qi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Define a sample function and its gradient/hessian***"
      ],
      "metadata": {
        "id": "biaEy2Zcy2NC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u6MUH_VxJc_"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    def func(x):\n",
        "        return x[0]**2 + x[1]**2 + 3 * x[0] * x[1]\n",
        "\n",
        "    def grad_func(x):\n",
        "        return np.array([2 * x[0] + 3 * x[1], 2 * x[1] + 3 * x[0]])\n",
        "\n",
        "    def hess_func(x):\n",
        "        return np.array([[2, 3], [3, 2]])\n",
        "\n",
        "    x0 = np.array([1.0, 1.0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    print(\"Fletcher-Reeves CG Method:\")\n",
        "    x_opt, f_opt, iters = fletcher_reeves_cg(func, grad_func, x0)\n",
        "    print(f\"Optimal point: {x_opt}, Optimal value: {f_opt}, Iterations: {iters}\")\n",
        "\n",
        "    print(\"\\nMarquardt Method:\")\n",
        "    x_opt, f_opt, iters = marquardt_method(func, grad_func, hess_func, x0)\n",
        "    print(f\"Optimal point: {x_opt}, Optimal value: {f_opt}, Iterations: {iters}\")\n",
        "\n",
        "    print(\"\\nQuasi-Newton Method:\")\n",
        "    x_opt, f_opt, iters = quasi_newton_method(func, grad_func, x0)\n",
        "    print(f\"Optimal point: {x_opt}, Optimal value: {f_opt}, Iterations: {iters}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0iLb50mxKnw",
        "outputId": "82036d7e-bd5f-4ea3-b633-fa313dcbf527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fletcher-Reeves CG Method:\n",
            "Optimal point: [6.71267333e-08 6.71267333e-08], Optimal value: 2.2529991634504326e-14, Iterations: 28\n",
            "\n",
            "Marquardt Method:\n",
            "Optimal point: [3.99912018e-09 3.99912018e-09], Optimal value: 7.996481097347236e-17, Iterations: 2\n",
            "\n",
            "Quasi-Newton Method:\n",
            "Optimal point: [0.00000000e+00 1.11022302e-16], Optimal value: 1.232595164407831e-32, Iterations: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rosenbrock’s and Powell’s quartic, Q3"
      ],
      "metadata": {
        "id": "8ifCQAO2Y0bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import minimize\n",
        "import time\n",
        "\n",
        "# the Rosenbrock\n",
        "def rosenbrock(x):\n",
        "    return 100 * (x[1] - x[0]**2)**2 + (1 - x[0])**2\n",
        "\n",
        "# Powell's quartic function\n",
        "def powell(x):\n",
        "    return (x[0] + 10 * x[1])**2 + 5 * (x[2] - x[3])**2 + (x[1] - 2 * x[2])**4 + 10 * (x[0] - x[3])**4\n",
        "\n",
        "# optimization methods\n",
        "methods = ['CG', 'BFGS', 'L-BFGS-B']\n",
        "\n",
        "# Rosenbrock function\n",
        "x0_rosenbrock = [-1.2, 1.0]\n",
        "results_rosenbrock = {}\n",
        "for method in methods:\n",
        "    start_time = time.time()\n",
        "    result = minimize(rosenbrock, x0_rosenbrock, method=method)\n",
        "    end_time = time.time()\n",
        "    results_rosenbrock[method] = {\n",
        "        \"iterations\": result.nit,\n",
        "        \"optimal_solution\": result.x,\n",
        "        \"optimal_value\": result.fun,\n",
        "        \"cpu_time\": end_time - start_time,\n",
        "    }\n",
        "\n",
        "# Powell's quartic function\n",
        "x0_powell = [3.0, -1.0, 0.0, 1.0]\n",
        "results_powell = {}\n",
        "for method in methods:\n",
        "    start_time = time.time()\n",
        "    result = minimize(powell, x0_powell, method=method)\n",
        "    end_time = time.time()\n",
        "    results_powell[method] = {\n",
        "        \"iterations\": result.nit,\n",
        "        \"optimal_solution\": result.x,\n",
        "        \"optimal_value\": result.fun,\n",
        "        \"cpu_time\": end_time - start_time,\n",
        "    }\n",
        "\n",
        "# results\n",
        "import pandas as pd\n",
        "def display_results(title, results):\n",
        "    df = pd.DataFrame(results).T\n",
        "    df.index.name = 'Method'\n",
        "    print(f\"\\n{title}\\n{'=' * len(title)}\")\n",
        "    print(df)\n",
        "\n",
        "display_results(\"Rosenbrock Function Results\", results_rosenbrock)\n",
        "display_results(\"Powell's Quartic Function Results\", results_powell)\n"
      ],
      "metadata": {
        "id": "i3kkvSITyR-g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc097b79-93f1-4b9b-be4b-be54243bcdb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Rosenbrock Function Results\n",
            "===========================\n",
            "         iterations                          optimal_solution optimal_value  \\\n",
            "Method                                                                        \n",
            "CG               37   [0.9999967786209817, 0.999993554925881]           0.0   \n",
            "BFGS             32  [0.9999955014961288, 0.9999909947807805]           0.0   \n",
            "L-BFGS-B         36  [0.9999961559660699, 0.9999924201132679]           0.0   \n",
            "\n",
            "          cpu_time  \n",
            "Method              \n",
            "CG         0.02531  \n",
            "BFGS      0.013093  \n",
            "L-BFGS-B   0.00937  \n",
            "\n",
            "Powell's Quartic Function Results\n",
            "=================================\n",
            "         iterations                                   optimal_solution  \\\n",
            "Method                                                                   \n",
            "CG               87  [0.008718096220010301, -0.0008718101760847037,...   \n",
            "BFGS             35  [0.005862295953901753, -0.0005862443582658075,...   \n",
            "L-BFGS-B         27  [0.0005201918658494535, -5.40782026186786e-05,...   \n",
            "\n",
            "         optimal_value  cpu_time  \n",
            "Method                            \n",
            "CG                 0.0  0.048364  \n",
            "BFGS               0.0  0.012682  \n",
            "L-BFGS-B           0.0  0.006511  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uDfo-VKXZInX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}