{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V5E1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fDFwg28q1_l2","outputId":"f83144b2-3241-479b-e090-6cdc405e5e2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== ResNet on MNIST: Hyperparameter optimization using Cuckoo Search ===\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 17.8MB/s]\n","100%|██████████| 28.9k/28.9k [00:00<00:00, 483kB/s]\n","100%|██████████| 1.65M/1.65M [00:00<00:00, 4.47MB/s]\n","100%|██████████| 4.54k/4.54k [00:00<00:00, 14.9MB/s]\n","[ResNet-MNIST] Cuckoo Search:  58%|█████▊    | 7/12 [43:42<31:01, 372.22s/it]"]}],"source":["import math\n","import random\n","import time\n","import numpy as np\n","from copy import deepcopy\n","from tqdm import trange\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","# Cuckoo Search Algorithm implementation\n","def cuckoo_search(objective_func, bounds, n_nests=15, pa=0.25, alpha=0.1,\n","                  n_iter=100, levy_lambda=1.5, minimize=True, verbose_prefix=\"\"):\n","    \"\"\"\n","    Cuckoo Search (CS) algorithm for optimization.\n","\n","    objective_func: The function to be optimized. It should accept a dictionary of parameters.\n","    bounds: A dictionary of parameter bounds: {'param_name': (min_val, max_val, 'type')}\n","           'type' can be 'float' or 'int'.\n","    n_nests: Number of host nests (and cuckoos).\n","    pa: Probability of alien eggs detection (discovery rate).\n","    alpha: Step size scaling factor.\n","    n_iter: Total number of iterations (generations).\n","    levy_lambda: Exponent for Levy flight.\n","    minimize: If True, objective_func is minimized; otherwise, it's maximized.\n","    verbose_prefix: Prefix for print statements during optimization.\n","    \"\"\"\n","    n_params = len(bounds)\n","    param_names = list(bounds.keys())\n","\n","    # Initialize nests (solutions) randomly\n","    nests = []\n","    for _ in range(n_nests):\n","        nest = {}\n","        for name, (min_val, max_val, p_type) in bounds.items():\n","            if p_type == 'float':\n","                nest[name] = random.uniform(min_val, max_val)\n","            elif p_type == 'int':\n","                nest[name] = random.randint(int(min_val), int(max_val))\n","        nests.append(nest)\n","\n","    # Evaluate initial nests\n","    fitness = [objective_func(nest) for nest in nests]\n","\n","    # Find the initial best nest\n","    if minimize:\n","        best_f_idx = np.argmin(fitness)\n","    else:\n","        best_f_idx = np.argmax(fitness)\n","    best_nest = deepcopy(nests[best_f_idx])\n","    best_fitness = fitness[best_f_idx]\n","\n","    # Main loop\n","    for iteration in trange(n_iter, desc=f\"{verbose_prefix}Cuckoo Search\"):\n","        # Generate new solutions (cuckoos) via Levy flights\n","        new_nests = []\n","        for i in range(n_nests):\n","            # Select a cuckoo randomly\n","            cuckoo = deepcopy(nests[i])\n","\n","            # Generate new solution using Levy flight\n","            # Based on Mantegna's algorithm for Levy flights\n","            sigma = (math.gamma(1 + levy_lambda) * math.sin(math.pi * levy_lambda / 2) / \\\n","                    (math.gamma((1 + levy_lambda) / 2) * levy_lambda *\n","                     (2**((levy_lambda - 1) / 2))))**(1 / levy_lambda)\n","            u = np.random.normal(0, sigma**2, n_params)\n","            v = np.random.normal(0, 1, n_params)\n","            step = u / (np.abs(v)**(1 / levy_lambda))\n","\n","            # Scale step and apply to solution\n","            step_size = alpha * step * (np.array(list(best_nest.values())) -\n","                                       np.array(list(cuckoo.values())))\n","\n","            new_cuckoo = {}\n","            for j, name in enumerate(param_names):\n","                min_val, max_val, p_type = bounds[name]\n","                if p_type == 'float':\n","                    new_cuckoo[name] = cuckoo[name] + step_size[j]\n","                    new_cuckoo[name] = max(min_val, min(max_val, new_cuckoo[name]))\n","                elif p_type == 'int':\n","                    new_cuckoo[name] = round(cuckoo[name] + step_size[j])\n","                    new_cuckoo[name] = int(max(min_val, min(max_val, new_cuckoo[name])))\n","            new_nests.append(new_cuckoo)\n","\n","        # Evaluate new cuckoos and replace old nests if better\n","        new_fitness = [objective_func(nest) for nest in new_nests]\n","        for i in range(n_nests):\n","            if (minimize and new_fitness[i] < fitness[i]) or \\\n","               (not minimize and new_fitness[i] > fitness[i]):\n","                nests[i] = deepcopy(new_nests[i])\n","                fitness[i] = new_fitness[i]\n","\n","        # Discover alien eggs (abandon nests)\n","        n_abandon = int(pa * n_nests)\n","        if n_abandon > 0:\n","            abandon_indices = random.sample(range(n_nests), n_abandon)\n","            for idx in abandon_indices:\n","                new_nest = {}\n","                for name, (min_val, max_val, p_type) in bounds.items():\n","                    if p_type == 'float':\n","                        new_nest[name] = random.uniform(min_val, max_val)\n","                    elif p_type == 'int':\n","                        new_nest[name] = random.randint(int(min_val), int(max_val))\n","                nests[idx] = new_nest\n","                fitness[idx] = objective_func(new_nest)\n","\n","        # Update best nest\n","        if minimize:\n","            current_best_f_idx = np.argmin(fitness)\n","        else:\n","            current_best_f_idx = np.argmax(fitness)\n","        if (minimize and fitness[current_best_f_idx] < best_fitness) or \\\n","           (not minimize and fitness[current_best_f_idx] > best_fitness):\n","            best_nest = deepcopy(nests[current_best_f_idx])\n","            best_fitness = fitness[current_best_f_idx]\n","\n","    return best_nest, best_fitness\n","\n","\n","# Simple ResNet Block\n","class BasicBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_channels != out_channels:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_channels)\n","            )\n","\n","    def forward(self, x):\n","        out = self.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = self.relu(out)\n","        return out\n","\n","\n","class SimpleResNet(nn.Module):\n","    def __init__(self, n_filters=16, n_blocks=2, drop=0.3, num_classes=10):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(1, n_filters, 3, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(n_filters)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        # Create residual blocks\n","        self.layer1 = self._make_layer(n_filters, n_filters, n_blocks, stride=1)\n","        self.layer2 = self._make_layer(n_filters, n_filters*2, n_blocks, stride=2)\n","\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.dropout = nn.Dropout(drop)\n","        self.fc = nn.Linear(n_filters*2, num_classes)\n","\n","        self.in_channels = n_filters\n","\n","    def _make_layer(self, in_channels, out_channels, n_blocks, stride):\n","        layers = []\n","        layers.append(BasicBlock(in_channels, out_channels, stride))\n","        for _ in range(1, n_blocks):\n","            layers.append(BasicBlock(out_channels, out_channels, stride=1))\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.relu(self.bn1(self.conv1(x)))\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.dropout(x)\n","        x = self.fc(x)\n","        return x\n","\n","\n","def resnet_mnist_objective(params):\n","    \"\"\"\n","    Objective function for ResNet on MNIST dataset.\n","\n","    params: dict e.g. {'lr':0.01, 'batch':64, 'n_filters':16, 'n_blocks':2, 'dropout':0.3}\n","    We'll train for small epochs and return validation loss (minimize).\n","    \"\"\"\n","    # Map parameters\n","    lr = float(params['lr'])\n","    batch = int(params['batch'])\n","    n_filters = int(params['n_filters'])\n","    n_blocks = int(params['n_blocks'])\n","    dropout = float(params['dropout'])\n","    epochs = 2  # Quick training for optimization\n","\n","    # Load MNIST dataset\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.1307,), (0.3081,))\n","    ])\n","\n","    trainset = torchvision.datasets.MNIST(root='./data', train=True,\n","                                          download=True, transform=transform)\n","    valset = torchvision.datasets.MNIST(root='./data', train=False,\n","                                        download=True, transform=transform)\n","\n","    # Use subset for faster optimization\n","    small_train_idx = list(range(0, 10000))\n","    small_val_idx = list(range(0, 1000))\n","\n","    train_subset = torch.utils.data.Subset(trainset, small_train_idx)\n","    val_subset = torch.utils.data.Subset(valset, small_val_idx)\n","\n","    trainloader = torch.utils.data.DataLoader(train_subset, batch_size=batch,\n","                                             shuffle=True, num_workers=0)\n","    valloader = torch.utils.data.DataLoader(val_subset, batch_size=batch,\n","                                           shuffle=False, num_workers=0)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # Create model\n","    model = SimpleResNet(n_filters=n_filters, n_blocks=n_blocks,\n","                        drop=dropout, num_classes=10).to(device)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","    # Train for a few epochs\n","    model.train()\n","    for e in range(epochs):\n","        for xb, yb in trainloader:\n","            xb, yb = xb.to(device), yb.to(device)\n","            optimizer.zero_grad()\n","            out = model(xb)\n","            loss = criterion(out, yb)\n","            loss.backward()\n","            optimizer.step()\n","\n","    # Evaluate validation loss\n","    model.eval()\n","    val_loss = 0.0\n","    n = 0\n","    with torch.no_grad():\n","        for xb, yb in valloader:\n","            xb, yb = xb.to(device), yb.to(device)\n","            out = model(xb)\n","            loss = criterion(out, yb)\n","            val_loss += loss.item() * xb.size(0)\n","            n += xb.size(0)\n","\n","    val_loss = val_loss / n\n","\n","    # Return validation loss (minimize)\n","    return val_loss\n","\n","\n","def run_resnet_mnist_optimization():\n","    \"\"\"\n","    Run Cuckoo Search optimization for ResNet on MNIST.\n","    \"\"\"\n","    print(\"\\n=== ResNet on MNIST: Hyperparameter optimization using Cuckoo Search ===\")\n","\n","    # Define parameter search space\n","    bounds = {\n","        'lr': (1e-4, 1e-2, 'float'),\n","        'batch': (32, 256, 'int'),\n","        'n_filters': (8, 32, 'int'),\n","        'n_blocks': (1, 3, 'int'),\n","        'dropout': (0.0, 0.5, 'float'),\n","    }\n","\n","    # Run Cuckoo Search\n","    best, best_f = cuckoo_search(\n","        resnet_mnist_objective,\n","        bounds,\n","        n_nests=8,          # Number of nests\n","        pa=0.25,            # Discovery rate\n","        alpha=0.1,          # Step size\n","        n_iter=12,          # Number of iterations\n","        levy_lambda=1.5,    # Levy flight exponent\n","        minimize=True,      # We want to minimize validation loss\n","        verbose_prefix=\"[ResNet-MNIST] \"\n","    )\n","\n","    print(f\"\\n[ResNet-MNIST] OPTIMIZATION COMPLETE!\")\n","    print(f\"[ResNet-MNIST] Best validation loss: {best_f:.6f}\")\n","    print(f\"[ResNet-MNIST] Best parameters:\")\n","    for param, value in best.items():\n","        print(f\"  - {param}: {value}\")\n","\n","    return best, best_f\n","\n","\n","if __name__ == \"__main__\":\n","    # Set random seeds for reproducibility\n","    random.seed(42)\n","    np.random.seed(42)\n","    torch.manual_seed(42)\n","\n","    # Run the optimization\n","    best_params, best_loss = run_resnet_mnist_optimization()"]},{"cell_type":"markdown","source":["START\n","\n","  ↓\n","\n","Initialize nests randomly\n","  \n","  ↓\n","\n","Evaluate all nests\n","\n","  ↓\n","\n","\n","Select best_nest\n","\n","  ↓\n","\n","\n","For each iteration:\n","\n","    ↓\n","\n","  Generate new cuckoos using Levy flight\n","\n","    ↓\n","\n","  Evaluate new cuckoos\n","\n","\n","    ↓\n","\n","  Replace nests if cuckoo is better\n","\n","    ↓\n","\n","  Abandon pa% of nests → random new nests\n","\n","    ↓\n","\n","\n","  Update global best_nest\n","\n","  ↑\n","\n","Repeat iteration\n","\n","  ↓\n","\n","Return best_nest and best_fitness\n","\n","  ↓\n","\n","END\n"],"metadata":{"id":"OZcyFfmt86pO"}},{"cell_type":"code","source":[],"metadata":{"id":"TaE_xcIn2Ent"},"execution_count":null,"outputs":[]}]}