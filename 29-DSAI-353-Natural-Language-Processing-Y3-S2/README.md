# DSAI 353 - Natural Language Processing (Y3-S2)

<div align="center">

**Spring 2024** | **Advanced AI Course** | **Research Component**

[![Materials](https://img.shields.io/badge/Materials-Complete-success)](.)
[![Projects](https://img.shields.io/badge/Projects-Multiple-blue)](.)
[![Skills](https://img.shields.io/badge/Skills-Transformers%20|%20BERT%20|%20Seq2Seq-orange)](.)

</div>

---

## ğŸ“‹ Course Overview

Comprehensive natural language processing course covering text processing, language models, and modern NLP architectures. Emphasis on Transformer-based models and their applications in various NLP tasks.

---

## ğŸ¯ Learning Outcomes Achieved

### NLP Fundamentals
- âœ… Text preprocessing and tokenization
- âœ… Word embeddings (Word2Vec, GloVe)
- âœ… Language modeling
- âœ… Sequence labeling

### Deep Learning for NLP
- âœ… RNNs for text (LSTM, GRU)
- âœ… Sequence-to-sequence models
- âœ… Attention mechanisms
- âœ… Transformer architecture

### Modern NLP
- âœ… BERT and pretrained models
- âœ… Fine-tuning strategies
- âœ… Named Entity Recognition
- âœ… Question answering

---

## ğŸ“š Topics Covered

### Module 1: NLP Basics (Weeks 1-3)
- Text preprocessing
- Tokenization and normalization
- N-gram models
- Word embeddings

### Module 2: Sequence Models (Weeks 4-7)
- RNNs for NLP
- Seq2Seq models
- Attention mechanisms
- Machine translation

### Module 3: Transformers (Weeks 8-11)
- Self-attention
- Transformer architecture
- BERT and variants
- GPT models overview

### Module 4: Applications (Weeks 12-14)
- Sentiment analysis
- Named Entity Recognition
- Question answering
- Text generation

---

## ğŸ’» Technical Projects

### Project: Arabic Dialect Sentiment Analyzer

**Objective**: Build sentiment analysis for dialectal Arabic

**Implementation**:
- AraBERT fine-tuning
- Custom preprocessing for Arabic dialects
- Handling code-switching
- API deployment

**Results**:
- High F1-score on Egyptian Arabic
- Robust handling of dialectal variations
- Production-ready API

[ğŸ“‚ GitHub Repository](https://github.com/Abdulrahmann-Omar)

**Technologies**: PyTorch, Transformers, FastAPI, AraBERT

---

## ğŸ“– Key Resources

### Textbooks
- **"Speech and Language Processing"** - Jurafsky & Martin
- **"Natural Language Processing with Transformers"** - Tunstall et al.

### Online Courses
- CS224n: NLP with Deep Learning (Stanford)

---

## ğŸ¯ Course Impact on Graduate Studies Preparation

NLP course provided:
- Strong foundation in modern NLP
- Transformer expertise
- Practical fine-tuning skills
- Research project leading toward publication

---

<div align="center">

**Key Takeaway**: Transformers have revolutionized NLP - understanding them deeply is essential for modern AI.

[â¬…ï¸ Back to All Courses](../README.md#-complete-course-catalog)

</div>
